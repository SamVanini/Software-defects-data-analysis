{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dca8ef36",
   "metadata": {},
   "source": [
    "# Software Defects Analysis & Prediction\n",
    "\n",
    "This dataset is compiled from five widely-used software defect datasets: JM1, KC1, CM1, KC2, and PC1, originally collected from NASA’s Metrics Data Program (MDP). These datasets contain static code metrics extracted from real-world software modules, paired with binary defect labels indicating whether each module contains defects (1) or not (0).\n",
    "\n",
    "Each module is represented by quantitative software engineering metrics such as lines of code, cyclomatic complexity, Halstead complexity measures, coupling factors, and operand/operator counts. These metrics serve as indicators of software quality and are commonly used for defect prediction in software engineering research.\n",
    "\n",
    "## Key Features\n",
    "\n",
    "**LOC (Lines of Code)** – Measures module size\n",
    "\n",
    "**CYCLO (Cyclomatic Complexity)** – Indicates decision structure complexity\n",
    "\n",
    "**LENGTH, VOLUME, DIFFICULTY** – Halstead complexity metrics\n",
    "\n",
    "**INT_FAN_IN / INT_FAN_OUT** – Input/output module dependencies\n",
    "\n",
    "**NUM_OPERATORS / NUM_OPERANDS** – Frequency of symbols used in code\n",
    "\n",
    "**BRANCH_COUNT** – Conditional logic and branching\n",
    "\n",
    "**DEFECT_LABEL** – Binary label (1 = Defective, 0 = Clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7a876c",
   "metadata": {},
   "source": [
    "## Step 0: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6612254c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "import seaborn as sb\n",
    "import dotenv\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b394ceeb",
   "metadata": {},
   "source": [
    "## Step 1: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c95f04b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1_000, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>LOC</th><th>CYCLO</th><th>LENGTH</th><th>VOLUME</th><th>DIFFICULTY</th><th>INT_FAN_IN</th><th>INT_FAN_OUT</th><th>NUM_OPERATORS</th><th>NUM_OPERANDS</th><th>BRANCH_COUNT</th><th>DEFECT_LABEL</th></tr><tr><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td></tr></thead><tbody><tr><td>0.779239</td><td>0.478261</td><td>0.274048</td><td>0.544918</td><td>0.564121</td><td>0.222222</td><td>0.444444</td><td>0.736196</td><td>0.807377</td><td>0.642857</td><td>0</td></tr><tr><td>0.595156</td><td>0.608696</td><td>0.742561</td><td>0.758597</td><td>0.450649</td><td>0.222222</td><td>0.0</td><td>0.576687</td><td>0.20082</td><td>0.142857</td><td>0</td></tr><tr><td>0.895502</td><td>0.0</td><td>0.968166</td><td>0.754277</td><td>0.672996</td><td>1.0</td><td>0.0</td><td>0.116564</td><td>0.020492</td><td>0.0</td><td>1</td></tr><tr><td>0.782007</td><td>0.565217</td><td>0.164706</td><td>0.017766</td><td>0.584106</td><td>0.0</td><td>1.0</td><td>0.615542</td><td>0.481557</td><td>0.5</td><td>0</td></tr><tr><td>0.757785</td><td>0.217391</td><td>0.5609</td><td>0.126125</td><td>0.52605</td><td>0.555556</td><td>0.222222</td><td>0.656442</td><td>0.655738</td><td>0.857143</td><td>1</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>0.577855</td><td>0.73913</td><td>0.331488</td><td>0.09195</td><td>0.603102</td><td>1.0</td><td>0.444444</td><td>0.460123</td><td>0.081967</td><td>0.214286</td><td>0</td></tr><tr><td>0.500346</td><td>0.304348</td><td>0.719031</td><td>0.553453</td><td>0.51187</td><td>0.666667</td><td>1.0</td><td>0.010225</td><td>0.713115</td><td>0.0</td><td>0</td></tr><tr><td>0.155017</td><td>0.869565</td><td>0.843253</td><td>0.641748</td><td>0.059249</td><td>1.0</td><td>0.666667</td><td>0.435583</td><td>0.848361</td><td>0.928571</td><td>1</td></tr><tr><td>0.367474</td><td>0.608696</td><td>0.803806</td><td>0.703938</td><td>0.287075</td><td>0.111111</td><td>1.0</td><td>0.419223</td><td>0.586066</td><td>0.5</td><td>1</td></tr><tr><td>0.077509</td><td>0.0</td><td>0.183391</td><td>0.373249</td><td>0.091656</td><td>0.333333</td><td>0.333333</td><td>0.134969</td><td>0.868852</td><td>0.071429</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1_000, 11)\n",
       "┌──────────┬──────────┬──────────┬──────────┬───┬───────────────┬──────────────┬──────────────┬──────────────┐\n",
       "│ LOC      ┆ CYCLO    ┆ LENGTH   ┆ VOLUME   ┆ … ┆ NUM_OPERATORS ┆ NUM_OPERANDS ┆ BRANCH_COUNT ┆ DEFECT_LABEL │\n",
       "│ ---      ┆ ---      ┆ ---      ┆ ---      ┆   ┆ ---           ┆ ---          ┆ ---          ┆ ---          │\n",
       "│ f64      ┆ f64      ┆ f64      ┆ f64      ┆   ┆ f64           ┆ f64          ┆ f64          ┆ i64          │\n",
       "╞══════════╪══════════╪══════════╪══════════╪═══╪═══════════════╪══════════════╪══════════════╪══════════════╡\n",
       "│ 0.779239 ┆ 0.478261 ┆ 0.274048 ┆ 0.544918 ┆ … ┆ 0.736196      ┆ 0.807377     ┆ 0.642857     ┆ 0            │\n",
       "│ 0.595156 ┆ 0.608696 ┆ 0.742561 ┆ 0.758597 ┆ … ┆ 0.576687      ┆ 0.20082      ┆ 0.142857     ┆ 0            │\n",
       "│ 0.895502 ┆ 0.0      ┆ 0.968166 ┆ 0.754277 ┆ … ┆ 0.116564      ┆ 0.020492     ┆ 0.0          ┆ 1            │\n",
       "│ 0.782007 ┆ 0.565217 ┆ 0.164706 ┆ 0.017766 ┆ … ┆ 0.615542      ┆ 0.481557     ┆ 0.5          ┆ 0            │\n",
       "│ 0.757785 ┆ 0.217391 ┆ 0.5609   ┆ 0.126125 ┆ … ┆ 0.656442      ┆ 0.655738     ┆ 0.857143     ┆ 1            │\n",
       "│ …        ┆ …        ┆ …        ┆ …        ┆ … ┆ …             ┆ …            ┆ …            ┆ …            │\n",
       "│ 0.577855 ┆ 0.73913  ┆ 0.331488 ┆ 0.09195  ┆ … ┆ 0.460123      ┆ 0.081967     ┆ 0.214286     ┆ 0            │\n",
       "│ 0.500346 ┆ 0.304348 ┆ 0.719031 ┆ 0.553453 ┆ … ┆ 0.010225      ┆ 0.713115     ┆ 0.0          ┆ 0            │\n",
       "│ 0.155017 ┆ 0.869565 ┆ 0.843253 ┆ 0.641748 ┆ … ┆ 0.435583      ┆ 0.848361     ┆ 0.928571     ┆ 1            │\n",
       "│ 0.367474 ┆ 0.608696 ┆ 0.803806 ┆ 0.703938 ┆ … ┆ 0.419223      ┆ 0.586066     ┆ 0.5          ┆ 1            │\n",
       "│ 0.077509 ┆ 0.0      ┆ 0.183391 ┆ 0.373249 ┆ … ┆ 0.134969      ┆ 0.868852     ┆ 0.071429     ┆ 0            │\n",
       "└──────────┴──────────┴──────────┴──────────┴───┴───────────────┴──────────────┴──────────────┴──────────────┘"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filedir = os.getenv(\"DATA_DIR\") or \"\"\n",
    "filename = os.getenv(\"DATASET_NAME\") or \"\"\n",
    "filedir = f'.\\\\..\\\\{filedir}'\n",
    "\n",
    "df = pl.read_csv(Path(filedir).joinpath(filename))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e32372",
   "metadata": {},
   "source": [
    "## Step 2: Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f549fb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1000, 11)  (1000 rows x 11 columns)\n",
      "\n",
      "Schema:\n",
      "  LOC                  Float64\n",
      "  CYCLO                Float64\n",
      "  LENGTH               Float64\n",
      "  VOLUME               Float64\n",
      "  DIFFICULTY           Float64\n",
      "  INT_FAN_IN           Float64\n",
      "  INT_FAN_OUT          Float64\n",
      "  NUM_OPERATORS        Float64\n",
      "  NUM_OPERANDS         Float64\n",
      "  BRANCH_COUNT         Float64\n",
      "  DEFECT_LABEL         Int64\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape: {df.shape}  ({df.shape[0]} rows x {df.shape[1]} columns)\\n')\n",
    "\n",
    "print('Schema:')\n",
    "for name, dtype in df.schema.items():\n",
    "    print(f'  {name:20s} {str(dtype)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8244e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive statistics:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 12)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>statistic</th><th>LOC</th><th>CYCLO</th><th>LENGTH</th><th>VOLUME</th><th>DIFFICULTY</th><th>INT_FAN_IN</th><th>INT_FAN_OUT</th><th>NUM_OPERATORS</th><th>NUM_OPERANDS</th><th>BRANCH_COUNT</th><th>DEFECT_LABEL</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>1000.0</td><td>1000.0</td><td>1000.0</td><td>1000.0</td><td>1000.0</td><td>1000.0</td><td>1000.0</td><td>1000.0</td><td>1000.0</td><td>1000.0</td><td>1000.0</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>0.520711</td><td>0.493304</td><td>0.509783</td><td>0.505971</td><td>0.502349</td><td>0.503556</td><td>0.510667</td><td>0.493988</td><td>0.512625</td><td>0.514643</td><td>0.326</td></tr><tr><td>&quot;std&quot;</td><td>0.289402</td><td>0.301158</td><td>0.289705</td><td>0.291389</td><td>0.284572</td><td>0.315975</td><td>0.3214</td><td>0.295131</td><td>0.276572</td><td>0.314337</td><td>0.468982</td></tr><tr><td>&quot;min&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;25%&quot;</td><td>0.278893</td><td>0.217391</td><td>0.255363</td><td>0.252745</td><td>0.263143</td><td>0.222222</td><td>0.222222</td><td>0.231084</td><td>0.280738</td><td>0.214286</td><td>0.0</td></tr><tr><td>&quot;50%&quot;</td><td>0.53218</td><td>0.478261</td><td>0.513841</td><td>0.522599</td><td>0.511867</td><td>0.555556</td><td>0.555556</td><td>0.494888</td><td>0.518443</td><td>0.571429</td><td>0.0</td></tr><tr><td>&quot;75%&quot;</td><td>0.767474</td><td>0.73913</td><td>0.761592</td><td>0.759421</td><td>0.750672</td><td>0.777778</td><td>0.777778</td><td>0.756646</td><td>0.741803</td><td>0.785714</td><td>1.0</td></tr><tr><td>&quot;max&quot;</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 12)\n",
       "┌────────────┬──────────┬──────────┬──────────┬───┬───────────────┬──────────────┬──────────────┬──────────────┐\n",
       "│ statistic  ┆ LOC      ┆ CYCLO    ┆ LENGTH   ┆ … ┆ NUM_OPERATORS ┆ NUM_OPERANDS ┆ BRANCH_COUNT ┆ DEFECT_LABEL │\n",
       "│ ---        ┆ ---      ┆ ---      ┆ ---      ┆   ┆ ---           ┆ ---          ┆ ---          ┆ ---          │\n",
       "│ str        ┆ f64      ┆ f64      ┆ f64      ┆   ┆ f64           ┆ f64          ┆ f64          ┆ f64          │\n",
       "╞════════════╪══════════╪══════════╪══════════╪═══╪═══════════════╪══════════════╪══════════════╪══════════════╡\n",
       "│ count      ┆ 1000.0   ┆ 1000.0   ┆ 1000.0   ┆ … ┆ 1000.0        ┆ 1000.0       ┆ 1000.0       ┆ 1000.0       │\n",
       "│ null_count ┆ 0.0      ┆ 0.0      ┆ 0.0      ┆ … ┆ 0.0           ┆ 0.0          ┆ 0.0          ┆ 0.0          │\n",
       "│ mean       ┆ 0.520711 ┆ 0.493304 ┆ 0.509783 ┆ … ┆ 0.493988      ┆ 0.512625     ┆ 0.514643     ┆ 0.326        │\n",
       "│ std        ┆ 0.289402 ┆ 0.301158 ┆ 0.289705 ┆ … ┆ 0.295131      ┆ 0.276572     ┆ 0.314337     ┆ 0.468982     │\n",
       "│ min        ┆ 0.0      ┆ 0.0      ┆ 0.0      ┆ … ┆ 0.0           ┆ 0.0          ┆ 0.0          ┆ 0.0          │\n",
       "│ 25%        ┆ 0.278893 ┆ 0.217391 ┆ 0.255363 ┆ … ┆ 0.231084      ┆ 0.280738     ┆ 0.214286     ┆ 0.0          │\n",
       "│ 50%        ┆ 0.53218  ┆ 0.478261 ┆ 0.513841 ┆ … ┆ 0.494888      ┆ 0.518443     ┆ 0.571429     ┆ 0.0          │\n",
       "│ 75%        ┆ 0.767474 ┆ 0.73913  ┆ 0.761592 ┆ … ┆ 0.756646      ┆ 0.741803     ┆ 0.785714     ┆ 1.0          │\n",
       "│ max        ┆ 1.0      ┆ 1.0      ┆ 1.0      ┆ … ┆ 1.0           ┆ 1.0          ┆ 1.0          ┆ 1.0          │\n",
       "└────────────┴──────────┴──────────┴──────────┴───┴───────────────┴──────────────┴──────────────┴──────────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Descriptive statistics:\\n')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c19c696d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null counts per column:\n",
      "shape: (1, 11)\n",
      "┌─────┬───────┬────────┬────────┬───┬───────────────┬──────────────┬──────────────┬──────────────┐\n",
      "│ LOC ┆ CYCLO ┆ LENGTH ┆ VOLUME ┆ … ┆ NUM_OPERATORS ┆ NUM_OPERANDS ┆ BRANCH_COUNT ┆ DEFECT_LABEL │\n",
      "│ --- ┆ ---   ┆ ---    ┆ ---    ┆   ┆ ---           ┆ ---          ┆ ---          ┆ ---          │\n",
      "│ u32 ┆ u32   ┆ u32    ┆ u32    ┆   ┆ u32           ┆ u32          ┆ u32          ┆ u32          │\n",
      "╞═════╪═══════╪════════╪════════╪═══╪═══════════════╪══════════════╪══════════════╪══════════════╡\n",
      "│ 0   ┆ 0     ┆ 0      ┆ 0      ┆ … ┆ 0             ┆ 0            ┆ 0            ┆ 0            │\n",
      "└─────┴───────┴────────┴────────┴───┴───────────────┴──────────────┴──────────────┴──────────────┘\n",
      "\n",
      "Duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "null_counts = df.null_count()\n",
    "print('Null counts per column:')\n",
    "print(null_counts)\n",
    "\n",
    "n_duplicates = df.shape[0] - df.unique().shape[0]\n",
    "print(f'\\nDuplicate rows: {n_duplicates}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e5e93b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution:\n",
      "shape: (2, 2)\n",
      "┌──────────────┬─────┐\n",
      "│ DEFECT_LABEL ┆ len │\n",
      "│ ---          ┆ --- │\n",
      "│ i64          ┆ u32 │\n",
      "╞══════════════╪═════╡\n",
      "│ 0            ┆ 674 │\n",
      "│ 1            ┆ 326 │\n",
      "└──────────────┴─────┘\n",
      "  Class 0: 674 (67.4%)\n",
      "  Class 1: 326 (32.6%)\n",
      "\n",
      "Imbalance ratio (minority/majority): 0.484\n",
      "Class distribution is reasonably balanced.\n"
     ]
    }
   ],
   "source": [
    "class_counts = df.group_by('DEFECT_LABEL').len().sort('DEFECT_LABEL')\n",
    "print('Class distribution:')\n",
    "print(class_counts)\n",
    "\n",
    "total = df.shape[0]\n",
    "for row in class_counts.iter_rows():\n",
    "    label, count = row\n",
    "    print(f'  Class {label}: {count} ({count/total*100:.1f}%)')\n",
    "\n",
    "# Flag imbalance\n",
    "majority = class_counts['len'].max()\n",
    "minority = class_counts['len'].min()\n",
    "ratio = minority / majority\n",
    "print(f'\\nImbalance ratio (minority/majority): {ratio:.3f}')\n",
    "if ratio < 0.43:  # roughly 30/70\n",
    "    print('Dataset is moderately imbalanced — stratified splitting recommended.')\n",
    "else:\n",
    "    print('Class distribution is reasonably balanced.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77aef181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean feature values per class:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>DEFECT_LABEL</th><th>LOC</th><th>CYCLO</th><th>LENGTH</th><th>VOLUME</th><th>DIFFICULTY</th><th>INT_FAN_IN</th><th>INT_FAN_OUT</th><th>NUM_OPERATORS</th><th>NUM_OPERANDS</th><th>BRANCH_COUNT</th></tr><tr><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>0</td><td>0.522796</td><td>0.498581</td><td>0.515211</td><td>0.513013</td><td>0.501868</td><td>0.506264</td><td>0.512364</td><td>0.49064</td><td>0.525861</td><td>0.500742</td></tr><tr><td>1</td><td>0.516401</td><td>0.482395</td><td>0.498562</td><td>0.491412</td><td>0.503344</td><td>0.497955</td><td>0.507157</td><td>0.50091</td><td>0.48526</td><td>0.543383</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 11)\n",
       "┌──────────────┬──────────┬──────────┬──────────┬───┬─────────────┬───────────────┬──────────────┬──────────────┐\n",
       "│ DEFECT_LABEL ┆ LOC      ┆ CYCLO    ┆ LENGTH   ┆ … ┆ INT_FAN_OUT ┆ NUM_OPERATORS ┆ NUM_OPERANDS ┆ BRANCH_COUNT │\n",
       "│ ---          ┆ ---      ┆ ---      ┆ ---      ┆   ┆ ---         ┆ ---           ┆ ---          ┆ ---          │\n",
       "│ i64          ┆ f64      ┆ f64      ┆ f64      ┆   ┆ f64         ┆ f64           ┆ f64          ┆ f64          │\n",
       "╞══════════════╪══════════╪══════════╪══════════╪═══╪═════════════╪═══════════════╪══════════════╪══════════════╡\n",
       "│ 0            ┆ 0.522796 ┆ 0.498581 ┆ 0.515211 ┆ … ┆ 0.512364    ┆ 0.49064       ┆ 0.525861     ┆ 0.500742     │\n",
       "│ 1            ┆ 0.516401 ┆ 0.482395 ┆ 0.498562 ┆ … ┆ 0.507157    ┆ 0.50091       ┆ 0.48526      ┆ 0.543383     │\n",
       "└──────────────┴──────────┴──────────┴──────────┴───┴─────────────┴───────────────┴──────────────┴──────────────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = [c for c in df.columns if c != 'DEFECT_LABEL']\n",
    "\n",
    "print('Mean feature values per class:\\n')\n",
    "per_class_mean = (\n",
    "    df.group_by('DEFECT_LABEL')\n",
    "    .agg([pl.col(c).mean().alias(c) for c in feature_cols])\n",
    "    .sort('DEFECT_LABEL')\n",
    ")\n",
    "per_class_mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fae10e",
   "metadata": {},
   "source": [
    "## Step 3: Data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381b8f06",
   "metadata": {},
   "source": [
    "## Step 4: Defects prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ef5a45",
   "metadata": {},
   "source": [
    "### Model 1: Logistic Regression\n",
    "\n",
    "#### The Core Idea\n",
    "\n",
    "Logistic Regression models the **probability** that an instance belongs to class 1 using the **logistic (sigmoid) function**.\n",
    "\n",
    "#### Mathematical Formulation\n",
    "\n",
    "##### 1. Linear Combination\n",
    "\n",
    "First, compute a linear combination of features:\n",
    "\n",
    "```\n",
    "z = β₀ + β₁x₁ + β₂x₂ + ... + βₙxₙ\n",
    "z = β₀ + Σ(βᵢ * xᵢ)\n",
    "```\n",
    "\n",
    "Where:\n",
    "\n",
    "- `x₁, x₂, ..., xₙ` are the features\n",
    "- `β₀, β₁, ..., βₙ` are the coefficients (weights) to be learned\n",
    "- `β₀` is the intercept (bias)\n",
    "\n",
    "##### 2. Sigmoid Function\n",
    "\n",
    "Transform the linear output to a probability using the **sigmoid function**:\n",
    "\n",
    "```\n",
    "P(y=1|x) = σ(z) = 1 / (1 + e^(-z))\n",
    "```\n",
    "\n",
    "Where:\n",
    "\n",
    "- `P(y=1|x)` is the probability that y=1 given features x\n",
    "- `e` is Euler's number (≈2.718)\n",
    "- The output is always between 0 and 1\n",
    "\n",
    "**Why sigmoid?** It maps any real number to a range [0, 1]\n",
    "\n",
    "```\n",
    "z → -∞    ⟹  P → 0\n",
    "z = 0     ⟹  P = 0.5\n",
    "z → +∞    ⟹  P → 1\n",
    "```\n",
    "\n",
    "##### 3. Decision Rule\n",
    "\n",
    "```\n",
    "Predict class 1 if P(y=1|x) ≥ 0.5\n",
    "Predict class 0 if P(y=1|x) < 0.5\n",
    "```\n",
    "\n",
    "#### Loss Function: Log Loss (Cross-Entropy)\n",
    "\n",
    "The model learns by minimizing the **log loss**:\n",
    "\n",
    "```\n",
    "L(β) = -1/m * Σ[yᵢ * log(P(yᵢ=1|xᵢ)) + (1-yᵢ) * log(1-P(yᵢ=1|xᵢ))]\n",
    "```\n",
    "\n",
    "Where:\n",
    "\n",
    "- `m` is the number of training examples\n",
    "- `yᵢ` is the actual label (0 or 1)\n",
    "- `P(yᵢ=1|xᵢ)` is the predicted probability\n",
    "\n",
    "**Intuition**:\n",
    "\n",
    "- If actual y=1 and we predict P=0.9, loss is small (-log(0.9) ≈ 0.1)\n",
    "- If actual y=1 and we predict P=0.1, loss is large (-log(0.1) ≈ 2.3)\n",
    "\n",
    "#### Regularization\n",
    "\n",
    "To prevent overfitting, add a penalty term:\n",
    "\n",
    "**L2 Regularization (Ridge):**\n",
    "\n",
    "```\n",
    "L(β) = Log Loss + λ * Σ(βᵢ²)\n",
    "```\n",
    "\n",
    "**L1 Regularization (Lasso):**\n",
    "\n",
    "```\n",
    "L(β) = Log Loss + λ * Σ|βᵢ|\n",
    "```\n",
    "\n",
    "Where `λ` controls regularization strength (larger λ = more regularization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf24b30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb94d0c5",
   "metadata": {},
   "source": [
    "### Model 2: Random Forest\n",
    "\n",
    "#### The Core Idea\n",
    "\n",
    "Build many **decision trees** on random subsets of data and features, then **average** their predictions.\n",
    "\n",
    "#### Mathematical Formulation\n",
    "\n",
    "##### 1. Single Decision Tree\n",
    "\n",
    "A decision tree splits data recursively to maximize **information gain** or minimize **impurity**.\n",
    "\n",
    "**Gini Impurity** (measure of randomness):\n",
    "\n",
    "```\n",
    "Gini(node) = 1 - Σ(pᵢ²)\n",
    "```\n",
    "\n",
    "Where:\n",
    "\n",
    "- `pᵢ` is the proportion of class i samples in the node\n",
    "- Perfect purity: Gini = 0 (all samples same class)\n",
    "- Maximum impurity: Gini = 0.5 (equal mix of classes)\n",
    "\n",
    "**Example:**\n",
    "\n",
    "```\n",
    "Node with 60 class-0 and 40 class-1 samples:\n",
    "p₀ = 60/100 = 0.6\n",
    "p₁ = 40/100 = 0.4\n",
    "Gini = 1 - (0.6² + 0.4²) = 1 - 0.52 = 0.48\n",
    "```\n",
    "\n",
    "**Information Gain** when splitting:\n",
    "\n",
    "```\n",
    "IG = Gini(parent) - Weighted_Average[Gini(left_child), Gini(right_child)]\n",
    "```\n",
    "\n",
    "The algorithm chooses splits that **maximize Information Gain**.\n",
    "\n",
    "##### 2. Bootstrap Aggregating (Bagging)\n",
    "\n",
    "Random Forest creates diversity through **bagging**:\n",
    "\n",
    "1. **Randomly sample** m instances from training data (with replacement)\n",
    "2. **Randomly select** k features at each split (typically k = √n_features)\n",
    "3. Build a decision tree on this subset\n",
    "4. Repeat for n_trees\n",
    "\n",
    "##### 3. Prediction by Voting\n",
    "\n",
    "For binary classification:\n",
    "\n",
    "```\n",
    "P(y=1|x) = 1/N * Σ[tree_i predicts 1]\n",
    "```\n",
    "\n",
    "Where N is the number of trees.\n",
    "\n",
    "**Final prediction:**\n",
    "\n",
    "```\n",
    "ŷ = 1 if P(y=1|x) ≥ 0.5, else 0\n",
    "```\n",
    "\n",
    "#### Why Does It Work?\n",
    "\n",
    "**Law of Large Numbers:** Average of many predictions is more stable than individual predictions.\n",
    "\n",
    "**Bias-Variance Tradeoff:**\n",
    "\n",
    "- Single tree: Low bias, high variance (overfits)\n",
    "- Random Forest: Low bias, low variance (averaging reduces variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a944f67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "926a0258",
   "metadata": {},
   "source": [
    "### Model 3: Gradient Boosting\n",
    "\n",
    "#### The Core Idea\n",
    "\n",
    "Build trees **sequentially**, where each tree corrects the errors of the previous trees.\n",
    "\n",
    "#### Mathematical Formulation\n",
    "\n",
    "##### 1. Additive Model\n",
    "\n",
    "The prediction is a **sum** of multiple weak learners:\n",
    "\n",
    "```\n",
    "F(x) = f₀(x) + η*f₁(x) + η*f₂(x) + ... + η*fₘ(x)\n",
    "```\n",
    "\n",
    "Where:\n",
    "\n",
    "- `F(x)` is the final prediction\n",
    "- `f₀(x)` is the initial prediction (usually mean)\n",
    "- `fᵢ(x)` are decision trees (weak learners)\n",
    "- `η` is the learning rate (0 < η ≤ 1)\n",
    "- `m` is the number of trees\n",
    "\n",
    "##### 2. Sequential Learning\n",
    "\n",
    "At each iteration t:\n",
    "\n",
    "**Step 1: Calculate residuals (errors)**\n",
    "\n",
    "```\n",
    "rᵢ⁽ᵗ⁾ = yᵢ - F⁽ᵗ⁻¹⁾(xᵢ)\n",
    "```\n",
    "\n",
    "**Step 2: Fit a new tree to residuals**\n",
    "\n",
    "```\n",
    "fₜ(x) ← fit_tree(X, r⁽ᵗ⁾)\n",
    "```\n",
    "\n",
    "**Step 3: Update the model**\n",
    "\n",
    "```\n",
    "F⁽ᵗ⁾(x) = F⁽ᵗ⁻¹⁾(x) + η * fₜ(x)\n",
    "```\n",
    "\n",
    "#### 3. For Binary Classification\n",
    "\n",
    "Use **log-odds** instead of class labels:\n",
    "\n",
    "```\n",
    "F(x) = log(P(y=1|x) / P(y=0|x))\n",
    "```\n",
    "\n",
    "Convert to probability:\n",
    "\n",
    "```\n",
    "P(y=1|x) = 1 / (1 + e^(-F(x)))\n",
    "```\n",
    "\n",
    "##### 4. Gradient Descent Intuition\n",
    "\n",
    "Gradient Boosting minimizes loss by following the **negative gradient**:\n",
    "\n",
    "```\n",
    "fₜ(x) ≈ -∂L/∂F(x)\n",
    "```\n",
    "\n",
    "Where L is the loss function (e.g., log loss).\n",
    "\n",
    "**Why \"Gradient\" Boosting?** Each new tree fits the **negative gradient** of the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a66b257",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22a11220",
   "metadata": {},
   "source": [
    "### Model 4: Support Vector Machine (SVM)\n",
    "\n",
    "#### The Core Idea\n",
    "\n",
    "Find the **hyperplane** that maximizes the **margin** between classes.\n",
    "\n",
    "#### Mathematical Formulation\n",
    "\n",
    "##### 1. Linear SVM (Linearly Separable Case)\n",
    "\n",
    "Find a hyperplane:\n",
    "\n",
    "```\n",
    "w·x + b = 0\n",
    "```\n",
    "\n",
    "Where:\n",
    "\n",
    "- `w` is the weight vector (perpendicular to hyperplane)\n",
    "- `b` is the bias (intercept)\n",
    "- `x` is the feature vector\n",
    "\n",
    "**Decision function:**\n",
    "\n",
    "```\n",
    "f(x) = sign(w·x + b)\n",
    "```\n",
    "\n",
    "If `f(x) > 0`, predict class +1; if `f(x) < 0`, predict class -1.\n",
    "\n",
    "##### 2. Margin Maximization\n",
    "\n",
    "The **margin** is the distance from the hyperplane to the nearest data point:\n",
    "\n",
    "```\n",
    "margin = 2 / ||w||\n",
    "```\n",
    "\n",
    "Where `||w||` is the Euclidean norm (magnitude) of w.\n",
    "\n",
    "**Optimization problem:**\n",
    "\n",
    "```\n",
    "Maximize: 2 / ||w||\n",
    "Subject to: yᵢ(w·xᵢ + b) ≥ 1 for all i\n",
    "```\n",
    "\n",
    "Equivalent to:\n",
    "\n",
    "```\n",
    "Minimize: (1/2)||w||²\n",
    "Subject to: yᵢ(w·xᵢ + b) ≥ 1 for all i\n",
    "```\n",
    "\n",
    "##### 3. Soft Margin (Non-linearly Separable)\n",
    "\n",
    "Allow some misclassifications using **slack variables** ξᵢ:\n",
    "\n",
    "```\n",
    "Minimize: (1/2)||w||² + C * Σξᵢ\n",
    "Subject to: yᵢ(w·xᵢ + b) ≥ 1 - ξᵢ\n",
    "            ξᵢ ≥ 0\n",
    "```\n",
    "\n",
    "Where:\n",
    "\n",
    "- `C` is the regularization parameter (larger C = fewer misclassifications allowed)\n",
    "- `ξᵢ` measures violation of margin for point i\n",
    "\n",
    "##### 4. Kernel Trick\n",
    "\n",
    "For non-linear decision boundaries, map data to higher dimension:\n",
    "\n",
    "```\n",
    "φ: x → φ(x)\n",
    "```\n",
    "\n",
    "**Radial Basis Function (RBF) Kernel:**\n",
    "\n",
    "```\n",
    "K(xᵢ, xⱼ) = exp(-γ||xᵢ - xⱼ||²)\n",
    "```\n",
    "\n",
    "Where:\n",
    "\n",
    "- `γ` controls the influence of a single training example\n",
    "- High γ: Only close points influence (simple, possibly overfit)\n",
    "- Low γ: Far points influence (more generalization)\n",
    "\n",
    "**Decision function with kernel:**\n",
    "\n",
    "```\n",
    "f(x) = sign(Σαᵢ yᵢ K(xᵢ, x) + b)\n",
    "```\n",
    "\n",
    "Where `αᵢ` are Lagrange multipliers (learned during training)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5080b7f",
   "metadata": {},
   "source": [
    "### Model 5: K-Nearest Neighbors (KNN)\n",
    "\n",
    "#### The Core Idea\n",
    "\n",
    "Classify based on the **majority vote** of the k nearest neighbors.\n",
    "\n",
    "#### Mathematical Formulation\n",
    "\n",
    "##### 1. Distance Metric\n",
    "\n",
    "**Euclidean Distance** (most common):\n",
    "\n",
    "```\n",
    "d(x, xᵢ) = √(Σ(x_j - xᵢ_j)²)\n",
    "```\n",
    "\n",
    "**Manhattan Distance:**\n",
    "\n",
    "```\n",
    "d(x, xᵢ) = Σ|x_j - xᵢ_j|\n",
    "```\n",
    "\n",
    "**Minkowski Distance** (generalization):\n",
    "\n",
    "```\n",
    "d(x, xᵢ) = (Σ|x_j - xᵢ_j|^p)^(1/p)\n",
    "```\n",
    "\n",
    "- p=1: Manhattan\n",
    "- p=2: Euclidean\n",
    "- p=∞: Chebyshev\n",
    "\n",
    "##### 2. Prediction Algorithm\n",
    "\n",
    "**For a new point x:**\n",
    "\n",
    "1. Calculate distance to all training points\n",
    "2. Find k nearest neighbors\n",
    "3. Take majority vote (or weighted vote)\n",
    "\n",
    "**Uniform weights:**\n",
    "\n",
    "```\n",
    "P(y=1|x) = (Number of neighbors with class 1) / k\n",
    "```\n",
    "\n",
    "**Distance weights:**\n",
    "\n",
    "```\n",
    "P(y=1|x) = Σ[wᵢ * I(yᵢ=1)] / Σwᵢ\n",
    "```\n",
    "\n",
    "Where:\n",
    "\n",
    "```\n",
    "wᵢ = 1 / d(x, xᵢ)\n",
    "```\n",
    "\n",
    "##### 3. Why K Matters\n",
    "\n",
    "- **Small k (e.g., k=1)**: Very sensitive to noise (high variance)\n",
    "- **Large k (e.g., k=100)**: Over-smoothed (high bias)\n",
    "- **Optimal k**: Usually √n or found by cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bafbd4",
   "metadata": {},
   "source": [
    "### Model 6: Naive Bayes\n",
    "\n",
    "#### The Core Idea\n",
    "\n",
    "Use **Bayes' Theorem** with the \"naive\" assumption that features are **independent** given the class.\n",
    "\n",
    "#### Mathematical Formulation\n",
    "\n",
    "##### 1. Bayes' Theorem\n",
    "\n",
    "```\n",
    "P(y|x) = P(x|y) * P(y) / P(x)\n",
    "```\n",
    "\n",
    "Where:\n",
    "\n",
    "- `P(y|x)` is the **posterior**: probability of class y given features x\n",
    "- `P(x|y)` is the **likelihood**: probability of observing x given class y\n",
    "- `P(y)` is the **prior**: probability of class y\n",
    "- `P(x)` is the **evidence**: probability of observing x\n",
    "\n",
    "##### 2. Naive Assumption\n",
    "\n",
    "Assume features are **independent** given the class:\n",
    "\n",
    "```\n",
    "P(x|y) = P(x₁|y) * P(x₂|y) * ... * P(xₙ|y)\n",
    "P(x|y) = ∏ P(xᵢ|y)\n",
    "```\n",
    "\n",
    "This simplifies computation dramatically\n",
    "\n",
    "##### 3. Classification Rule\n",
    "\n",
    "Predict the class with highest posterior probability:\n",
    "\n",
    "```\n",
    "ŷ = argmax_y P(y|x)\n",
    "  = argmax_y P(y) * ∏ P(xᵢ|y)\n",
    "```\n",
    "\n",
    "##### 4. Gaussian Naive Bayes\n",
    "\n",
    "For continuous features, assume **Gaussian (normal) distribution**:\n",
    "\n",
    "```\n",
    "P(xᵢ|y) = (1 / √(2πσᵢy²)) * exp(-(xᵢ - μᵢy)² / (2σᵢy²))\n",
    "```\n",
    "\n",
    "Where:\n",
    "\n",
    "- `μᵢy` is the mean of feature i for class y\n",
    "- `σᵢy` is the standard deviation of feature i for class y\n",
    "\n",
    "##### 5. Log-Probabilities\n",
    "\n",
    "In practice, use **log-probabilities** to avoid numerical underflow:\n",
    "\n",
    "```\n",
    "log P(y|x) ∝ log P(y) + Σ log P(xᵢ|y)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ec5a5a",
   "metadata": {},
   "source": [
    "### Model 7: Neural Network (MLPClassifier)\n",
    "\n",
    "### The Core Idea\n",
    "\n",
    "Stack multiple layers of **artificial neurons** that learn to transform inputs into outputs through **backpropagation**.\n",
    "\n",
    "### Mathematical Formulation\n",
    "\n",
    "#### 1. Single Neuron (Perceptron)\n",
    "\n",
    "A neuron computes:\n",
    "\n",
    "```\n",
    "z = w₁x₁ + w₂x₂ + ... + wₙxₙ + b\n",
    "a = σ(z)\n",
    "```\n",
    "\n",
    "Where:\n",
    "\n",
    "- `z` is the weighted sum (linear combination)\n",
    "- `a` is the activation (output after non-linearity)\n",
    "- `σ` is the activation function\n",
    "- `w` are weights, `b` is bias\n",
    "\n",
    "#### 2. Activation Functions\n",
    "\n",
    "**ReLU (Rectified Linear Unit)** - most popular:\n",
    "\n",
    "```\n",
    "ReLU(z) = max(0, z)\n",
    "```\n",
    "\n",
    "- Fast to compute\n",
    "- Helps with vanishing gradient problem\n",
    "\n",
    "**Sigmoid:**\n",
    "\n",
    "```\n",
    "sigmoid(z) = 1 / (1 + e^(-z))\n",
    "```\n",
    "\n",
    "- Smooth gradient\n",
    "- Output in [0, 1]\n",
    "\n",
    "**Tanh (Hyperbolic Tangent):**\n",
    "\n",
    "```\n",
    "tanh(z) = (e^z - e^(-z)) / (e^z + e^(-z))\n",
    "```\n",
    "\n",
    "- Output in [-1, 1]\n",
    "- Zero-centered\n",
    "\n",
    "#### 3. Multi-Layer Perceptron (MLP)\n",
    "\n",
    "**Forward Propagation:**\n",
    "\n",
    "For layer ℓ:\n",
    "\n",
    "```\n",
    "z^[ℓ] = W^[ℓ] * a^[ℓ-1] + b^[ℓ]\n",
    "a^[ℓ] = σ(z^[ℓ])\n",
    "```\n",
    "\n",
    "**Example with 2 hidden layers:**\n",
    "\n",
    "```\n",
    "Input: x\n",
    "Hidden layer 1: a^[1] = σ(W^[1] * x + b^[1])\n",
    "Hidden layer 2: a^[2] = σ(W^[2] * a^[1] + b^[2])\n",
    "Output: ŷ = σ(W^[3] * a^[2] + b^[3])\n",
    "```\n",
    "\n",
    "#### 4. Loss Function\n",
    "\n",
    "**Binary Cross-Entropy:**\n",
    "\n",
    "```\n",
    "L(ŷ, y) = -[y * log(ŷ) + (1-y) * log(1-ŷ)]\n",
    "```\n",
    "\n",
    "#### 5. Backpropagation\n",
    "\n",
    "Compute gradients using **chain rule**:\n",
    "\n",
    "```\n",
    "∂L/∂W^[ℓ] = ∂L/∂a^[ℓ] * ∂a^[ℓ]/∂z^[ℓ] * ∂z^[ℓ]/∂W^[ℓ]\n",
    "```\n",
    "\n",
    "**Gradient Descent Update:**\n",
    "\n",
    "```\n",
    "W^[ℓ] ← W^[ℓ] - α * ∂L/∂W^[ℓ]\n",
    "b^[ℓ] ← b^[ℓ] - α * ∂L/∂b^[ℓ]\n",
    "```\n",
    "\n",
    "Where `α` is the learning rate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
